{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b54ce88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1034cef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPEN_API_KEY = os.getenv('OPEN_API_KEY')\n",
    "\n",
    "LANGSMITH_TRACING = os.getenv('LANGSMITH_TRACING')\n",
    "LANGSMITH_API_KEY = os.getenv('LANGSMITH_API_KEY')\n",
    "LANGSMITH_PROJECT = os.getenv('LANGSMITH_PROJECT')\n",
    "LANGSMITH_ENDPOINT = os.getenv('LANGSMITH_ENDPOINT')\n",
    "\n",
    "TAVILY_API_KEY = os.getenv('TAVILY_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff44dec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1001c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tavily import TavilyClient\n",
    "\n",
    "# Initialize Tavily client\n",
    "tavily_client = TavilyClient(api_key=TAVILY_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "431ad60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "from typing import TypedDict, List\n",
    "from typing import Annotated\n",
    "from operator import add\n",
    "from typing import Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61e28e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TavilySearchOutput(BaseModel):\n",
    "    title: str\n",
    "    url: str\n",
    "    content: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd1c54ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AgentState(TypedDict):\n",
    "    query: str\n",
    "    tavilySearchOutput: List[TavilySearchOutput]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20cfcbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes your search term, looks it up on three dataset-heavy sites, throws away useless or duplicate links, and gives you back a clean list of dataset pages you can actually use.\n",
    "\n",
    "def tavily_search_tool(state: AgentState):\n",
    "    \"\"\"Search Kaggle + Hugging Face + GitHub and return up to 10 most relevant, mixed, deduped dataset links.\"\"\"\n",
    "    query = state[\"query\"]\n",
    "\n",
    "    site_queries = {\n",
    "        \"kaggle\": f\"{query} dataset site:kaggle.com/datasets\",\n",
    "        \"huggingface\": f\"{query} dataset site:huggingface.co/datasets\",\n",
    "        \"github\": f\"{query} dataset site:github.com (dataset OR data)\"\n",
    "    }\n",
    "\n",
    "    def which_site(url: str) -> str | None:\n",
    "        u = url.lower()\n",
    "        if \"kaggle.com/datasets/\" in u:\n",
    "            return \"kaggle\"\n",
    "        if \"huggingface.co/datasets/\" in u:\n",
    "            return \"huggingface\"\n",
    "        if \"github.com\" in u and any(p in u for p in [\"/data\", \"/dataset\", \"/datasets\", \"/blob/\", \"/tree/\", \"/raw/\", \".csv\", \".xlsx\", \".json\"]):\n",
    "            return \"github\"\n",
    "        return None\n",
    "\n",
    "    def relevance_score(site: str, title: str, url: str, content: str) -> float:\n",
    "        t = (title or \"\").lower()\n",
    "        u = (url or \"\").lower()\n",
    "        c = (content or \"\").lower()\n",
    "        score = 0.0\n",
    "        # Strong signals of downloadable/data-bearing resources\n",
    "        if any(x in u for x in [\".csv\", \".xlsx\", \".json\", \"/download\", \"/resolve/\", \"/raw/\"]):\n",
    "            score += 3.0\n",
    "        if any(x in c for x in [\"csv\", \"xlsx\", \"json\", \"download\"]):\n",
    "            score += 2.0\n",
    "        # Query keyword overlap (simple)\n",
    "        for tok in set(query.lower().split()):\n",
    "            if tok and (tok in t or tok in c):\n",
    "                score += 0.5\n",
    "        # Site priors (dataset-centric sites get a small boost)\n",
    "        if site in (\"kaggle\", \"huggingface\"):\n",
    "            score += 0.5\n",
    "        return score\n",
    "\n",
    "    candidates: list[tuple[str, TavilySearchOutput, float]] = []\n",
    "    seen_urls: set[str] = set()\n",
    "\n",
    "    # Collect per-site, compute scores\n",
    "    for site, q in site_queries.items():\n",
    "        try:\n",
    "            r = tavily_client.search(query=q, search_depth=\"basic\", max_results=10)\n",
    "        except Exception:\n",
    "            continue\n",
    "        if not isinstance(r, dict) or \"results\" not in r:\n",
    "            continue\n",
    "        for h in r[\"results\"]:\n",
    "            url = h.get(\"url\", \"\") if isinstance(h, dict) else \"\"\n",
    "            site_name = which_site(url) if url else None\n",
    "            if site_name is None:\n",
    "                continue\n",
    "            if url in seen_urls:\n",
    "                continue\n",
    "            seen_urls.add(url)\n",
    "            title = h.get(\"title\", \"\")\n",
    "            content = h.get(\"content\", \"\")\n",
    "            tso = TavilySearchOutput(title=title, url=url, content=content)\n",
    "            score = relevance_score(site_name, title, url, content)\n",
    "            candidates.append((site_name, tso, score))\n",
    "\n",
    "    # Sort globally by relevance (desc)\n",
    "    candidates.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    # Seed with top-1 per site if available to ensure a mix\n",
    "    selected: list[TavilySearchOutput] = []\n",
    "    used_urls: set[str] = set()\n",
    "    sites_present = {s for s, _, _ in candidates}\n",
    "    for s in (\"kaggle\", \"huggingface\", \"github\"):\n",
    "        if s in sites_present:\n",
    "            for site_name, tso, _ in candidates:\n",
    "                if site_name == s and tso.url not in used_urls:\n",
    "                    selected.append(tso)\n",
    "                    used_urls.add(tso.url)\n",
    "                    break\n",
    "        if len(selected) >= 3:\n",
    "            break\n",
    "\n",
    "    # Fill remaining slots by overall relevance\n",
    "    for _, tso, _ in candidates:\n",
    "        if len(selected) >= 10:\n",
    "            break\n",
    "        if tso.url in used_urls:\n",
    "            continue\n",
    "        selected.append(tso)\n",
    "        used_urls.add(tso.url)\n",
    "\n",
    "    # Cap to 10\n",
    "    selected = selected[:10]\n",
    "\n",
    "    return {\"tavilySearchOutput\": selected}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7fed2c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tavilySearchOutput': [TavilySearchOutput(title='Novel Corona Virus 2019 Dataset - Kaggle', url='https://www.kaggle.com/datasets/sudalairajkumar/novel-corona-virus-2019-dataset', content='Content. This dataset has daily level information on the number of affected cases, deaths and recovery from 2019 novel coronavirus. Please note that this is a'),\n",
       "  TavilySearchOutput(title='xhluca/publichealth-qa · Datasets at Hugging Face', url='https://huggingface.co/datasets/xhluca/publichealth-qa', content='COVID-19 is a new disease, caused be a novel (or new) coronavirus that has not previously been seen in humans. The name of this disease was selected following'),\n",
       "  TavilySearchOutput(title='awesome-data/coronavirus.md at main - GitHub', url='https://github.com/datasets/awesome-data/blob/main/coronavirus.md', content='This dataset includes time series data tracking the number of people affected by COVID-19 worldwide, including: confirmed tested cases of Coronavirus infection'),\n",
       "  TavilySearchOutput(title='Covid Cases and Deaths WorldWide - Kaggle', url='https://www.kaggle.com/datasets/themrityunjaypathak/covid-cases-and-deaths-worldwide', content='About Dataset\\u200b\\u200b Coronavirus disease (COVID-19) is an infectious disease caused by the SARS-CoV-2 virus. Most people infected with the virus will experience mild'),\n",
       "  TavilySearchOutput(title='COVID-19 Open Research Dataset Challenge (CORD-19) - Kaggle', url='https://www.kaggle.com/datasets/allen-institute-for-ai/CORD-19-research-challenge', content='# COVID-19 Open Research Dataset Challenge (CORD-19) ## COVID-19 Open Research Dataset Challenge (CORD-19) ## About Dataset This freely available dataset is provided to the global research community to apply recent advances in natural language processing and other AI techniques to generate new insights in support of the ongoing fight against this infectious disease. This allows the worldwide AI research community the opportunity to apply text and data mining approaches to find answers to questions within, and connect insights across, this content in support of the ongoing COVID-19 response efforts worldwide. ### What have you used this dataset for? ### How would you describe this dataset?'),\n",
       "  TavilySearchOutput(title='COVID-19 Dataset - Kaggle', url='https://www.kaggle.com/datasets/meirnizri/covid19-dataset/data', content='The raw dataset consists of 21 different features and 1,048,576 unique patients. In the Boolean features, 1 means \"yes\" and 2 means \"no\". values as 97 and 99'),\n",
       "  TavilySearchOutput(title='COVID-19 Symptoms Checker - Kaggle', url='https://www.kaggle.com/datasets/iamhungundji/covid19-symptoms-checker', content='These data will help to identify whether any person is having a coronavirus disease or not based on some pre-defined standard symptoms.'),\n",
       "  TavilySearchOutput(title='Diagnosis of COVID-19 and its clinical spectrum - Kaggle', url='https://www.kaggle.com/datasets/einsteindata4u/covid19', content='The dataset reflects the complexity of decision making during routine clinical care, as opposed to what happens on a more controlled research setting, and data'),\n",
       "  TavilySearchOutput(title='COVID-QU-Ex Dataset - Kaggle', url='https://www.kaggle.com/datasets/anasmohammedtahir/covidqu', content='COVID-QU-Ex Dataset. The researchers of Qatar University have compiled the COVID-QU-Ex dataset, which consists of 33,920 chest X-ray (CXR) images including:.'),\n",
       "  TavilySearchOutput(title='COVID-19 Dataset - Kaggle', url='https://www.kaggle.com/datasets/imdevskp/corona-virus-report', content='Number of Confirmed, Death and Recovered cases every day across the globe.')]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = AgentState(query=\"Coronvirus diseases\")\n",
    "\n",
    "tavily_search_tool(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca55ff8",
   "metadata": {},
   "source": [
    "# Get datasest from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235fe02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/sudalairajkumar/novel-corona-virus-2019-dataset\n",
      "Downloading novel-corona-virus-2019-dataset.zip to ./data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8.52M/8.52M [00:00<00:00, 1.68GB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "api.dataset_download_files(\n",
    "    'sudalairajkumar/novel-corona-virus-2019-dataset',\n",
    "    path='./data',\n",
    "    force=True,\n",
    "    quiet=False,\n",
    "    unzip=True\n",
    ")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146ff5ca",
   "metadata": {},
   "source": [
    "# Tool to download Kaggle Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb6027f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/sudalairajkumar/novel-corona-virus-2019-dataset\n",
      "{'csv': ['./data/time_series_covid_19_confirmed_US.csv', './data/time_series_covid_19_recovered.csv', './data/time_series_covid_19_deaths_US.csv', './data/covid_19_data.csv', './data/time_series_covid_19_deaths.csv', './data/time_series_covid_19_confirmed.csv'], 'excel': []}\n"
     ]
    }
   ],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import os\n",
    "import re\n",
    "\n",
    "def download_kaggle_files(url: str, data_dir: str = './data') -> dict[str, list[str]]:\n",
    "    \"\"\"\n",
    "    Given a Kaggle dataset URL, downloads the dataset using the Kaggle API,\n",
    "    unzips it, and returns a dictionary with lists of CSV and Excel file paths extracted.\n",
    "\n",
    "    Args:\n",
    "        url (str): The Kaggle dataset URL, e.g. 'https://www.kaggle.com/datasets/sudalairajkumar/novel-corona-virus-2019-dataset' or 'https://www.kaggle.com/datasets/einsteindata4u/covid19'\n",
    "        data_dir (str): Directory to download and extract files to.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, List[str]]: Dictionary with keys 'csv' and 'excel', each mapping to a list of file paths.\n",
    "    \"\"\"\n",
    "    # Extract dataset slug from URL\n",
    "    m = re.search(r'kaggle\\.com/datasets/([^/]+/[^/?#]+)', url)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Could not parse Kaggle dataset slug from URL: {url}\")\n",
    "    dataset_slug = m.group(1)\n",
    "\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    api.dataset_download_files(\n",
    "        dataset_slug,\n",
    "        path=data_dir,\n",
    "        force=True,\n",
    "        quiet=True,\n",
    "        unzip=True\n",
    "    )\n",
    "\n",
    "    # Find all CSV and Excel files in the data_dir\n",
    "    csv_files = []\n",
    "    excel_files = []\n",
    "    for root, _, files in os.walk(data_dir):\n",
    "        for f in files:\n",
    "            if f.lower().endswith('.csv'):\n",
    "                csv_files.append(os.path.join(root, f))\n",
    "            elif f.lower().endswith('.xlsx') or f.lower().endswith('.xls'):\n",
    "                excel_files.append(os.path.join(root, f))\n",
    "    return {\"csv\": csv_files, \"excel\": excel_files}\n",
    "\n",
    "# Example usage:\n",
    "tabular_files = download_kaggle_files('https://www.kaggle.com/datasets/sudalairajkumar/novel-corona-virus-2019-dataset')\n",
    "print(tabular_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d193d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
